{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f24cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional,Embedding, Flatten, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cleantext\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4ee03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"train.csv\")\n",
    "df2 = pd.read_csv('hate.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a16603ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['is_bad'] = df1.apply(lambda row: 0 if (row['toxic'] == 0 and row['severe_toxic'] ==0 and row['obscene']==0 and \n",
    "                                           row['threat']==0 and row['insult'] == 0 and row['identity_hate'] == 0) else 1, axis=1)\n",
    "\n",
    "\n",
    "df2['is_bad'] = df2.apply(lambda row: 1 if (row['class'] == 0 or row['class'] == 1 ) else 0, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9c9eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(string):\n",
    "    string = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",string).split())\n",
    "    string = cleantext.clean(string, extra_spaces=True, lowercase=True, numbers=True, punct=True)\n",
    "    return string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18fe3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['clean_text'] = df1['comment_text'].apply(cleaning)   \n",
    "df2['clean_text'] = df2['tweet'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96849d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['id','comment_text','toxic','severe_toxic','obscene','threat','insult','identity_hate'], axis=1, inplace=True)\n",
    "df2.drop(['Unnamed: 0','count','hate_speech','offensive_language','neither','class', 'tweet'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e610f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_bad                                         clean_text\n",
      "0       0  explanation why the edits made under my userna...\n",
      "1       0  d aww he matches this background colour i m se...\n",
      "2       0  hey man i m really not trying to edit war it s...\n",
      "3       0  more i can t make any real suggestions on impr...\n",
      "4       0  you sir are my hero any chance you remember wh...\n",
      "   is_bad                                         clean_text\n",
      "0       0  rt as a woman you shouldn t complain about cle...\n",
      "1       1  rt boy dats cold tyga dwn bad for cuffin dat h...\n",
      "2       1  rt dawg rt you ever fuck a bitch and she start...\n",
      "3       1         rt g anderson based she look like a tranny\n",
      "4       1  rt the shit you hear about me might be true or...\n"
     ]
    }
   ],
   "source": [
    "print(df1.head())\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1775ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_bad</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_bad                                         clean_text\n",
       "0       0  explanation why the edits made under my userna...\n",
       "1       0  d aww he matches this background colour i m se...\n",
       "2       0  hey man i m really not trying to edit war it s...\n",
       "3       0  more i can t make any real suggestions on impr...\n",
       "4       0  you sir are my hero any chance you remember wh..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e52808c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184354"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73f16140",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50000\n",
    "embedding_dim = 16\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token='<oov>')\n",
    "\n",
    "tokenizer.fit_on_texts(df['clean_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18813451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170077"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index  = tokenizer.word_index\n",
    "word_count = len(word_index)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46e362cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_bad</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[677, 78, 2, 133, 135, 183, 30, 658, 4286, 112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[154, 13939, 51, 2564, 14, 552, 3698, 4, 68, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[400, 365, 4, 68, 138, 15, 248, 3, 80, 319, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[62, 4, 36, 22, 100, 59, 299, 1402, 16, 2061, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[8, 1609, 21, 30, 3281, 59, 1036, 8, 556, 43, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_bad                                          sequences\n",
       "0       0  [677, 78, 2, 133, 135, 183, 30, 658, 4286, 112...\n",
       "1       0  [154, 13939, 51, 2564, 14, 552, 3698, 4, 68, 4...\n",
       "2       0  [400, 365, 4, 68, 138, 15, 248, 3, 80, 319, 11...\n",
       "3       0  [62, 4, 36, 22, 100, 59, 299, 1402, 16, 2061, ...\n",
       "4       0  [8, 1609, 21, 30, 3281, 59, 1036, 8, 556, 43, ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sequences'] = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "df.drop(['clean_text'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49762ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    147509\n",
       "1     36845\n",
       "Name: is_bad, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Index(df['is_bad']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ca9339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(x) for x in df['sequences'].tolist()])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5213a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(df['sequences'])\n",
    "labels = np.array(df['is_bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2826463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([677, 78, 2, 133, 135, 183, 30, 658, 4286, 11238, 985, 89, 340, 48, 2164, 22, 11239, 55, 6712, 16, 63, 2546, 153, 4, 2839, 38, 120, 1164, 15391, 2718, 5, 52, 60, 22, 247, 2, 369, 34, 2, 42, 31, 149, 4, 68, 3266, 90]),\n",
       "       list([154, 13939, 51, 2564, 14, 552, 3698, 4, 68, 4383, 2440, 24, 98, 42, 967, 186]),\n",
       "       list([400, 365, 4, 68, 138, 15, 248, 3, 80, 319, 11, 19, 55, 10, 14, 564, 9, 2172, 488, 497, 108, 5, 543, 3, 39, 327, 133, 360, 6, 30, 42, 31, 51, 219, 3, 418, 62, 40, 2, 2333, 96, 2, 716, 471]),\n",
       "       ...,\n",
       "       list([1377, 7683, 1608, 809, 2558, 6333, 49, 4, 2572, 1645, 4410, 75, 132]),\n",
       "       list([41920, 234, 2936, 366, 16823, 8, 1187]),\n",
       "       list([41756, 1, 35043, 19792, 2732, 546, 4387, 6, 3847, 3148, 2064, 1175, 560, 7, 22935])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e72e8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = pad_sequences(sequences=sequences, maxlen=max_len, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "951fb381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184354, 1403)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86f8e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential([\n",
    "    Embedding(num_words,embedding_dim, input_length=max_len),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e4959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6bdab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "4033/4033 [==============================] - 219s 54ms/step - loss: 0.1966 - accuracy: 0.9349 - val_loss: 0.2674 - val_accuracy: 0.8981\n",
      "Epoch 2/6\n",
      "4033/4033 [==============================] - 220s 55ms/step - loss: 0.0918 - accuracy: 0.9669 - val_loss: 0.4210 - val_accuracy: 0.8918\n",
      "Epoch 3/6\n",
      "4033/4033 [==============================] - 219s 54ms/step - loss: 0.0766 - accuracy: 0.9721 - val_loss: 0.2797 - val_accuracy: 0.9032\n",
      "Epoch 4/6\n",
      "4033/4033 [==============================] - 218s 54ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.3364 - val_accuracy: 0.9011\n",
      "Epoch 5/6\n",
      "4033/4033 [==============================] - 219s 54ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.3650 - val_accuracy: 0.9015\n",
      "Epoch 6/6\n",
      "4033/4033 [==============================] - 218s 54ms/step - loss: 0.0426 - accuracy: 0.9840 - val_loss: 0.3284 - val_accuracy: 0.9063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22996ebca88>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_data,labels,validation_split=0.3,epochs = 6, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8de525b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: abusive-text-filter-model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: abusive-text-filter-model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('abusive-text-filter-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "365b80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the tokenizer\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22537ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's load the tokenizer and the model again just to show how it is done\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "imported_model = tf.keras.models.load_model('abusive-text-filter-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6970d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please insert your textI always dream about your beautiful face\n",
      "This is clean\n"
     ]
    }
   ],
   "source": [
    "text = str(input(\"Please insert your text\"))\n",
    "   \n",
    "\n",
    "text = tokenizer.texts_to_sequences([text])\n",
    "prediction = imported_model.predict_classes(text)\n",
    "\n",
    "if prediction == 1:\n",
    "    print(\"This is abusive\")\n",
    "else:\n",
    "    print(\"This is clean\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
